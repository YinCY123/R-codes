---
title: "Pre-Processing"
author: "yincy"
date: "6/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pre-Processing

-   Creating Dummy Variables\
-   Zero-and Near Zero-Variance Predictors\
-   Identifying Correlated Predictors\
-   Linear Dependencies\
-   The `preProcess` Function\
-   Centering and Scaling\
-   Imputation\
-   Transforming Predictors\
-   Putting It All Together\
-   Class Distance Calculations

`caret` includes several functions to pre-process the predictor data. It assumes that all of the data are numeric (i.e. factors have been converted to dummy variables via `model.matrix`, `dummyVars` or other means).

Note that the later chapter on using `recipes` with `train` shows how that approach can offer a more diverse and customizable interface to pre-processing in the package.

## Creating Dummy Variables
The function `dummyVars` can be used to generate a complete (less than full rank parameterized) set of dummy variables from one or more factors. The function takes a formula and a data set and outputs an object that can be used to create the dummy variables using the predict method.  

For example, the `etitanic` data set in the `earth` package includes two factors: `pclass` (passenger class, with levels 1st, 2nd, 3rd) and `sex` (with levels female, male). The base R function `model.matrix` would generate the following variables:  

```{r, message=FALSE}
library(earth)
library(caret)
library(tidyverse)
data(etitanic)

model.matrix(survived ~ ., data = etitanic) %>% head
```

Using `dummyVars`:  

```{r}
dummies <- dummyVars(survived ~., data = etitanic)

predict(dummies, newdata = etitanic) %>% head
```

Note there is no intercept and each factor has a dummy variable for each level, so this parameterization may not be useful for some model functions, such as `lm`.  

## Zero- and Near Zero-Variance Predictors
In some situations, the data generating mechanism can create predictors that only have a single unique value (i.e. a “zero-variance predictor”). For many models (excluding tree-based models), this may cause the model to crash or the fit to be unstable.  

Similarly, predictors might have only a handful of unique values that occur with very low frequencies. For example, in the drug resistance data, the `nR11` descriptor (number of 11-membered rings) data have a few unique numeric values that are highly unbalanced:  

```{r}
data(mdrr)

table(mdrrDescr$nR11) %>% as.data.frame()
```

The concern here that these predictors may become zero-variance predictors when the data are split into cross-validation/bootstrap sub-samples or that a few samples may have an undue influence on the model. These “near-zero-variance” predictors may need to be identified and eliminated prior to modeling.  

To identify these types of predictors, the following two metrics can be calculated:  

- *the frequency of the most prevalent value over the second most frequent value* (called the “frequency ratio’’), which would be near one for well-behaved predictors and very large for highly-unbalanced data and  

- *the “percent of unique values’’ is the number of unique values divided by the total number of samples* (times 100) that approaches zero as the granularity of the data increases   

If the frequency ratio is greater than a pre-specified threshold and the unique value percentage is less than a threshold, we might consider a predictor to be near zero-variance.  

We would not want to falsely identify data that have low granularity but are evenly distributed, such as data from a discrete uniform distribution. Using both criteria should not falsely detect such predictors.  

Looking at the MDRR data, the `nearZeroVar` function can be used to identify near zero-variance variables (the `saveMetrics` argument can be used to show the details and usually defaults to `FALSE`):  

```{r}
nzv <- nearZeroVar(mdrrDescr, saveMetrics = TRUE)

nzv[nzv$nzv, ]
```

```{r}
nzv <- nearZeroVar(mdrrDescr)
filteredDescr <- mdrrDescr[, -nzv]
```


















